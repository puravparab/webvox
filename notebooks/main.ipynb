{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4163a49d-c287-4082-a995-56df63673caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from utils import Content, login_hf, load_model\n",
    "login_hf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57d4ce-fae5-4d31-a2cc-f9f023a608a6",
   "metadata": {},
   "source": [
    "# Webvox\n",
    "Get audio summaries of any website, blog or paper\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/puravparab/webvox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006bbb7-7488-43ab-9eed-ffddd47ae40c",
   "metadata": {},
   "source": [
    "---\n",
    "## Table of Contents\n",
    "\n",
    "1. [Data](#1.-Data-)\n",
    "    - 1.1 [Blog](#1.1-Blog-)\n",
    "    - 1.2 [Website](#Website-)\n",
    "    - 1.3 [Paper](#1.2-Paper-)\n",
    "2. [Summarization](#2.-Summarization-)\n",
    "    - 2.1 [Llama 3.2B](#2.1-Llama-3.2-3B-Instruct-GGUF-)\n",
    "3. [Audio](#Audio-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85525b68-120c-49cb-b082-9b4034f93b5e",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data <a id='1.-Data-'></a>\n",
    "\n",
    "Let's import data from blogs, websites and papers that we can summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcc19f-0146-4740-911a-662efb45a147",
   "metadata": {},
   "source": [
    "### 1.1 Blog <a id='1.1-Blog-'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ed1bae-f843-4ffd-b387-b505e9c34940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 1582\n",
      "\n",
      "Blog content:\n",
      "'Founder Mode September 2024 At a YC event last week Brian Chesky gave a talk that everyone who\n",
      "was there will remember. Most founders I talked to afterward said\n",
      "it was the best they'd ever heard. Ron Conway, for the first time\n",
      "in his life, forgot to take notes. I'm not going to try to reproduce\n",
      "it here. Instead I want to talk about a question it raised. The theme of Brian's talk was that the conve'\n"
     ]
    }
   ],
   "source": [
    "# Insert url of a blog below\n",
    "url = \"https://paulgraham.com/foundermode.html\"\n",
    "\n",
    "blog = Content(url, 'blog')\n",
    "blog.scrape()\n",
    "print(f\"Token count: {blog.token_count}\")\n",
    "print(f\"\\nBlog content:\\n'{blog.text[:400]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c726e33-a43c-4880-be1a-edbd343fb65f",
   "metadata": {},
   "source": [
    "### 1.2 Paper <a id='1.2-Paper-'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8edc1c3-ab00-4da0-98d5-e6595567726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 12519\n",
      "\n",
      "Blog content:\n",
      "'Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. 1 Introduction Recurrent neural networks, long short-term memory [ 13 ] and gated recurrent [ 7 ]'\n"
     ]
    }
   ],
   "source": [
    "# Insert url of a paper below\n",
    "url = \"https://ar5iv.labs.arxiv.org/html/1706.03762\"\n",
    "\n",
    "paper = Content(url, 'blog')\n",
    "paper.scrape()\n",
    "print(f\"Token count: {paper.token_count}\")\n",
    "print(f\"\\nBlog content:\\n'{paper.text[1754:3000]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be115e0a-5064-46db-ae47-db34f3d66a4b",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Summarization <a id='2.-Summarization-'></a>\n",
    "\n",
    "Using various LLMs to summarize content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54fb7b-3ed8-446c-a257-a832e6a993b3",
   "metadata": {},
   "source": [
    "### 2.1 Llama-3.2-3B-Instruct-GGUF <a id='Llama-3.2-3B-Instruct-GGUF-'></a>\n",
    "We are using 4 bit quantized version of Llama 3.2B Instruct to summarize\n",
    "\n",
    "https://huggingface.co/lmstudio-community/Llama-3.2-3B-Instruct-GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b64ac1-a397-4f02-abd3-a55fc6fc1681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model: `Llama-3.2-3B-Instruct-Q4_K_M.gguf` from models/\n"
     ]
    }
   ],
   "source": [
    "# import model from hugging face\n",
    "llm = load_model(\n",
    "    repo_id=\"lmstudio-community/Llama-3.2-3B-Instruct-GGUF\",\n",
    "\tfilename=\"Llama-3.2-3B-Instruct-Q4_K_M.gguf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08470ad5-f05b-4892-88a8-a706a141ee0e",
   "metadata": {},
   "source": [
    "**Inference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0a0db15-39e9-43fb-b43a-40ea2d4e57ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here's a summary of the content:\n",
      "\n",
      "The author attended a YC (Y Combinator) event where Brian Chesky, Airbnb's founder, gave a talk that was widely praised. Chesky argued that conventional wisdom on how to run larger companies is incorrect and has damaged many successful founders. He shared his own experience, which he credits to studying Steve Jobs' approach to running Apple. Chesky claimed that many successful founders, who were in attendance, also followed the same conventional advice, but ended up with negative results. The author, along with Ron Conway, a venture capitalist, wondered why so many founders were given the same misguided advice as they grew their companies. After\n",
      "\n",
      "\n",
      "CPU times: user 26.3 s, sys: 38.1 ms, total: 26.3 s\n",
      "Wall time: 5.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that accurately summarizes content given to you.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Summarize the following content:\\n\\n{blog.text[:1500]}\"}\n",
    "]\n",
    "\n",
    "output = llm.create_chat_completion(\n",
    "    messages=messages\n",
    ")\n",
    "print(output[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29889dc-37b6-4cb5-a9f3-40c11cd8feb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
