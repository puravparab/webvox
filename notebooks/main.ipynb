{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4163a49d-c287-4082-a995-56df63673caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b57d4ce-fae5-4d31-a2cc-f9f023a608a6",
   "metadata": {},
   "source": [
    "# Webvox\n",
    "Get audio summaries of any website, blog or paper\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/puravparab/webvox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006bbb7-7488-43ab-9eed-ffddd47ae40c",
   "metadata": {},
   "source": [
    "---\n",
    "## Table of Contents\n",
    "\n",
    "1. [Data](#Data-)\n",
    "    - 1.1. [Blog](#Blog-)\n",
    "    - 1.2. [Website](#Website-)\n",
    "    - 1.3. [Paper](#Paper-)\n",
    "2. [Summarization](#Summarization-)\n",
    "3. [Audio](#Audio-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85525b68-120c-49cb-b082-9b4034f93b5e",
   "metadata": {},
   "source": [
    "---\n",
    "## Data <a id='Data-'></a>\n",
    "\n",
    "Let's import data from blogs, websites and papers that we can summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c3a67-677f-4d44-8808-d183c6892d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcc19f-0146-4740-911a-662efb45a147",
   "metadata": {},
   "source": [
    "### Blog <a id='Blog-'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed1bae-f843-4ffd-b387-b505e9c34940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert url of a blog below\n",
    "url = \"https://paulgraham.com/foundermode.html\"\n",
    "\n",
    "blog = Content(url, 'blog')\n",
    "blog.scrape()\n",
    "if blog.text:\n",
    "    print(blog.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c726e33-a43c-4880-be1a-edbd343fb65f",
   "metadata": {},
   "source": [
    "### Paper <a id='Paper-'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8edc1c3-ab00-4da0-98d5-e6595567726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert url of a paper below\n",
    "url = \"https://ar5iv.labs.arxiv.org/html/1706.03762\"\n",
    "\n",
    "paper = Content(url, 'blog')\n",
    "paper.scrape()\n",
    "if paper.text:\n",
    "    print(paper.text[1754:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be115e0a-5064-46db-ae47-db34f3d66a4b",
   "metadata": {},
   "source": [
    "## Summarization <a id='Summarization-'></a>\n",
    "\n",
    "Using an LLM to summarize content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54fb7b-3ed8-446c-a257-a832e6a993b3",
   "metadata": {},
   "source": [
    "### Llama 3.2 1B Instruct\n",
    "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9d618-5bdb-414f-a0e4-92e60f9c8664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Login to Hugging Face\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN not found in environment variables\")\n",
    "login(token=hf_token)\n",
    "\n",
    "# Load the model\n",
    "model_name = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d051af-1314-4acf-9997-de17bbf4983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog._tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb94379-2005-41f4-8ab8-56ccf046a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from transformers import TextIteratorStreamer\n",
    "# from threading import Thread\n",
    "\n",
    "# def summarize_blog_streaming(blog_text, max_length=4000):\n",
    "#     prompt = f\"Summarize the following blog post:\\n\\n{blog_text}\\n\\nSummary:\"\n",
    "    \n",
    "#     # Tokenize the input\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=6000, truncation=True)\n",
    "    \n",
    "#     # Create a streamer\n",
    "#     streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)\n",
    "    \n",
    "#     # Generate the summary in a separate thread\n",
    "#     generation_kwargs = dict(\n",
    "#         inputs,\n",
    "#         streamer=streamer,\n",
    "#         max_new_tokens=max_length,\n",
    "#         num_return_sequences=1,\n",
    "#         do_sample=True,\n",
    "#         temperature=0.7,\n",
    "#         top_p=0.95,\n",
    "#     )\n",
    "    \n",
    "#     thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "#     thread.start()\n",
    "    \n",
    "#     # Stream the output\n",
    "#     print(\"Streaming summary:\")\n",
    "#     generated_text = \"\"\n",
    "#     for new_text in streamer:\n",
    "#         print(new_text, end=\"\", flush=True)\n",
    "#         generated_text += new_text\n",
    "    \n",
    "#     # Extract only the generated summary, removing the input prompt\n",
    "#     summary = generated_text.split(\"Summary:\")[1].strip()\n",
    "    \n",
    "#     return summary\n",
    "\n",
    "# summary = summarize_blog_streaming(blog.text)\n",
    "# print(\"\\n\\nFinal Summary:\")\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c24fb8-2abe-4112-a59d-1ed0e42a7607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
